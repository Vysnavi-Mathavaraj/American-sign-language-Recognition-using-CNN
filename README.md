# Introduction

Sign language is a form of visual communication which involves a complex combination of hand movements. Certain placements of fingers can represent individual characters, while a complete motion of characters and phrases translate to a full sentence or gesture. The National Center for Health Statistics estimates that 28 million Americans (about 10% of the population) use sign language gestures as a means of non-verbal communication to express their thoughts and emotions (Jay, 2021). But non-signers find it extremely difficult to understand, hence trained sign language interpreters are needed during medical and legal appointments, educational and training sessions. Over the past five years, there has been an increasing demand for interpreters which can be expensive and intrusive. An efficient solution would be to use an application that can recognize the sign language and convert them into English language Speech. 

## Objective

With recent advances in deep learning and computer vision there has been promising progress in the fields of motion and gesture recognition using deep learning and computer vision-based techniques. The purpose of this project is to study and build a Sign Language to text and Speech translation system with OpenCV, Keras/TensorFlow using Deep Learning and Computer Vision concepts in order to communicate using American Sign Language(ASL) based gestures in real-time video streams.

ASL â€“ American Sign Language is a complete, natural language that has the same linguistic properties as spoken languages, with grammar that differs from English. ASL is expressed by movements of the hands and face. It is the primary language of many North Americans who are deaf and hard of hearing and is used by some hearing people as well (American sign language).

CNN - A convolutional neural network is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data. CNNs are powerful image processing, artificial intelligence that use deep learning to perform both generative and descriptive tasks, often using machine vison that includes image and video recognition, along with recommender systems and natural language processing (Albawi et al., 2017).

OpenCV - OpenCV is a huge open-source library for computer vision, machine learning, and image processing. OpenCV supports a wide variety of programming languages like Python, C++, Java, etc. It can process images and videos to identify objects, faces, or even the handwriting of a human (Opencv-python).

## Dataset

The dataset is available on Kaggle as the ASL Alphabet Dataset. https://www.kaggle.com/grassknoted/asl-alphabet

## Scope Of Project

A. Model should be able to identify hand signs using minimum reference images.

B. Model should work on the real-time webcam video feed.

C. It should be deployed as webapp.

## Steps to be followed to run this project -

STEP 1:
**$ pip install -r requirements.txt**

STEP 2:
**$ streamlit run app.py**

STEP 3:
**You can now view your Streamlit app in your browser. Local URL: http://localhost:8501**

